Spring Cloud Sleuth
====================
Adrian Cole, Spencer Gibb, Marcin Grzejszczak, Dave Syer, Jay Bryant

include::_attributes.adoc[]

*{spring-cloud-version}*

:doctype: book

include::overview.adoc[]

include::features.adoc[]

include::setup.adoc[]

== How Sleuth works

Spring Cloud Sleuth is a layer over https://github.com/openzipkin/brave[Brave].

Brave is a distributed tracing instrumentation library. Brave typically
intercepts production requests to gather timing data, correlate and propagate
trace contexts.

Trace data, also called spans, are typically reported to https://zipkin.io[Zipkin].
Zipkin is an Open Source tracing system, which includes a UI and various
collectors, such as HTTP and messaging.

Many Open Source and commercial products accept https://zipkin.io/zipkin-api/#/default/post_spans[Zipkin format].
Some options are documented https://zipkin.io/pages/extensions_choices.html[here],
but many are not. If you cannot use Zipkin and your product isn't listed, clarify
with your support representative and have them update that page. In many cases,
products already support Zipkin format, they just don't document it.

Traces connect from service to service using header propagation. The default
format is https://github.com/openzipkin/b3-propagation[B3]. Similar to data
formats, you can configure alternate header formats also, provided trace and
span IDs are compatible with B3. Most notably, this means the trace ID and span
IDs are lower-case hex, not UUIDs. Besides trace identifiers, other properties
(Baggage) can also be passed along with the request. Remote Baggage must be
predefined, but is flexible otherwise.

Sleuth configures everything you need to get started with tracing. Sleuth
configures where trace data (spans) are reported to, how many traces to keep
(sampling), if remote fields (baggage) are sent, and which libraries are traced.
Sleuth also adds annotation based tracing features and some instrumentation not
available otherwise, such as Reactor. If cannot find the configuration you are
looking for in the documentation, ask https://gitter.im/spring-cloud/spring-cloud-sleuth[Gitter]
before assuming something cannot be done.

=== Brave Basics

Most instrumentation work is done for you by default. Sleuth provides beans to
allow you to change what's traced, and it even provides annotations to avoid
using tracing libraries! All of this is explained later in this document.

That said, you might want to know more about how things work underneath. Here
are some pointers.

Here are the most core types you might use:
* `SpanCustomizer` - to change the span currently in progress
* `Tracer` - to get a start new spans ad-hoc

Here are the most relevant links from the OpenZipkin Brave project:
* [Brave's core library](https://github.com/openzipkin/brave/tree/master/brave)
* [Baggage (propagated fields)](https://github.com/openzipkin/brave/tree/master/brave#baggage)
* [HTTP tracing](https://github.com/openzipkin/brave/tree/master/instrumentation/http)

== Sampling

Sampling only applies to tracing backends, such as Zipkin. Trace IDs appear in logs regardless of
sample rate. Sampling is a way to prevent overloading the system, by consistently tracing some, but
not all requests.

The default rate of 10 traces per second is controlled by the `spring.sleuth.sampler.rate`
property and applies when we know Sleuth is used for reasons besides logging. Use a rate above 100
traces per second with extreme caution as it can overload your tracing system.

The sampler can be set by Java Config also, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=always_sampler,indent=0]
----

TIP: You can set the HTTP header `b3` to `1`, or, when doing messaging, you can set the `spanFlags` header to `1`.
Doing so forces the current request to be sampled regardless of configuration.

== Baggage
Baggage are fields that are propagated with the trace, optionally out of process. You can use
properties to define fields that have no special configuration such as name mapping:

 * `spring.sleuth.remote-fields` is a list of header names to accept and propagate to remote services.
 * `spring.sleuth.local-fields` is a list of names to propagate locally

No prefixing applies with these keys. What you set is literally what is used.

A name set in either of these properties will result in a `BaggageField` of the same name.

In order to automatically set the baggage values to Slf4j's MDC, you have to set
the `spring.sleuth.baggage.correlation-fields` property with a list of whitelisted
local or remote keys. E.g. `spring.sleuth.baggage.correlation-fields=country-code` will set the
value of the `country-code` baggage into MDC.

IMPORTANT: Remember that adding entries to MDC can drastically decrease the performance of your application!

If you want to add the baggage entries as tags, to make it possible to search for spans via the baggage entries, you can set the value of
`spring.sleuth.baggage.tag-fields` with a list of whitelisted baggage keys. To disable the feature you have to pass the `spring.sleuth.propagation.tag.enabled=false` property.

=== Java configuration

If you need to do anything more advanced than above, do not define properties and instead use a
`@Bean` config for the baggage fields you use.
 * `BaggagePropagationCustomizer` sets up baggage fields
   * Add a `SingleBaggageField` to control header names for a `BaggageField`.
 * `CorrelationScopeCustomizer` sets up MDC fields
   * Add a `SingleCorrelationField` to change the MDC name of a `BaggageField` or if updates flush.

== Instrumentation

Spring Cloud Sleuth automatically instruments all your Spring applications, so you should not have to do anything to activate it.
The instrumentation is added by using a variety of technologies according to the stack that is available. For example, for a servlet web application, we use a `Filter`, and, for Spring Integration, we use `ChannelInterceptors`.

You can customize the keys used in span tags.
To limit the volume of span data, an HTTP request is, by default, tagged only with a handful of metadata, such as the status code, the host, and the URL.
You can add request headers by configuring `spring.sleuth.keys.http.headers` (a list of header names).

NOTE: Tags are collected and exported only if there is a `Sampler` that allows it. By default, there is no such `Sampler`, to ensure that there is no danger of accidentally collecting too much data without configuring something).

== Span lifecycle

You can do the following operations on the Span by means of `brave.Tracer`:

* <<creating-and-finishing-spans, start>>: When you start a span, its name is assigned and the start timestamp is recorded.
* <<creating-and-finishing-spans, close>>: The span gets finished (the end time of the span is recorded) and, if the span is sampled, it is eligible for collection (for example, to Zipkin).
* <<continuing-spans, continue>>: A new instance of span is created.
It is a copy of the one that it continues.
* <<continuing-spans, detach>>: The span does not get stopped or closed.
It only gets removed from the current thread.
* <<creating-spans-with-explicit-parent, create with explicit parent>>: You can create a new span and set an explicit parent for it.

TIP: Spring Cloud Sleuth creates an instance of `Tracer` for you. In order to use it, you can autowire it.

=== Creating and finishing spans [[creating-and-finishing-spans]]

You can manually create spans by using the `Tracer`, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=manual_span_creation,indent=0]
----

In the preceding example, we could see how to create a new instance of the span.
If there is already a span in this thread, it becomes the parent of the new span.

IMPORTANT: Always clean after you create a span. Also, always finish any span that you want to send to Zipkin.

IMPORTANT: If your span contains a name greater than 50 chars, that name is truncated to 50 chars.
Your names have to be explicit and concrete. Big names lead to latency issues and sometimes even exceptions.

[[continuing-spans]]
=== Continuing Spans

Sometimes, you do not want to create a new span but you want to continue one. An example of such a
situation might be as follows:

* *AOP*: If there was already a span created before an aspect was reached, you might not want to create a new span.

To continue a span, you can use `brave.Tracer`, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=manual_span_continuation,indent=0]
----

[[creating-spans-with-explicit-parent]]
=== Creating a Span with an explicit Parent

You might want to start a new span and provide an explicit parent of that span.
Assume that the parent of a span is in one thread and you want to start a new span in another thread.
In Brave, whenever you call `nextSpan()`, it creates a span in reference to the span that is currently in scope.
You can put the span in scope and then call `nextSpan()`, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=manual_span_joining,indent=0]
----

IMPORTANT: After creating such a span, you must finish it. Otherwise it is not reported (for example, to Zipkin).

== Naming spans

Picking a span name is not a trivial task. A span name should depict an operation name.
The name should be low cardinality, so it should not include identifiers.

Since there is a lot of instrumentation going on, some span names are artificial:

* `controller-method-name` when received by a Controller with a method name of `controllerMethodName`
* `async` for asynchronous operations done with wrapped `Callable` and `Runnable` interfaces.
* Methods annotated with `@Scheduled` return the simple name of the class.

Fortunately, for asynchronous processing, you can provide explicit naming.

=== `@SpanName` Annotation

You can name the span explicitly by using the `@SpanName` annotation, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=span_name_annotation,indent=0]
----

In this case, when processed in the following manner, the span is named `calculateTax`:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=span_name_annotated_runnable_execution,indent=0]
----

=== `toString()` method

It is pretty rare to create separate classes for `Runnable` or `Callable`.
Typically, one creates an anonymous instance of those classes.
You cannot annotate such classes.
To overcome that limitation, if there is no `@SpanName` annotation present, we check whether the class has a custom implementation of the `toString()` method.

Running such code leads to creating a span named `calculateTax`, as shown in the following example:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=span_name_to_string_runnable_execution,indent=0]
----

== Managing Spans with Annotations

You can manage spans with a variety of annotations.

=== Rationale

There are a number of good reasons to manage spans with annotations, including:

* API-agnostic means to collaborate with a span. Use of annotations lets users add to a span with no library dependency on a span api.
Doing so lets Sleuth change its core API to create less impact to user code.
* Reduced surface area for basic span operations. Without this feature, you must use the span api, which has lifecycle commands that could be used incorrectly.
By only exposing scope, tag, and log functionality, you can collaborate without accidentally breaking span lifecycle.
* Collaboration with runtime generated code. With libraries such as Spring Data and Feign, the implementations of interfaces are generated at runtime.
Consequently, span wrapping of objects was tedious.
Now you can provide annotations over interfaces and the arguments of those interfaces.

=== Creating New Spans

If you do not want to create local spans manually, you can use the `@NewSpan` annotation.
Also, we provide the `@SpanTag` annotation to add tags in an automated fashion.

Now we can consider some examples of usage.

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=annotated_method,indent=0]
----

Annotating the method without any parameter leads to creating a new span whose name equals the annotated method name.

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=custom_name_on_annotated_method,indent=0]
----

If you provide the value in the annotation (either directly or by setting the `name` parameter), the created span has the provided value as the name.

[source,java]
----
// method declaration
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=custom_name_and_tag_on_annotated_method,indent=0]

// and method execution
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=execution,indent=0]
----

You can combine both the name and a tag. Let's focus on the latter.
In this case, the value of the annotated method's parameter runtime value becomes the value of the tag.
In our sample, the tag key is `testTag`, and the tag value is `test`.

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=name_on_implementation,indent=0]
----

You can place the `@NewSpan` annotation on both the class and an interface.
If you override the interface's method and provide a different value for the `@NewSpan` annotation, the most
concrete one wins (in this case `customNameOnTestMethod3` is set).

=== Continuing Spans

If you want to add tags and annotations to an existing span, you can use the `@ContinueSpan` annotation, as shown in the following example:

[source,java]
----
// method declaration
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=continue_span,indent=0]

// method execution
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SleuthSpanCreatorAspectTests.java[tags=continue_span_execution,indent=0]
----

(Note that, in contrast with the `@NewSpan` annotation ,you can also add logs with the `log` parameter.)

That way, the span gets continued and:

* Log entries named `testMethod11.before` and `testMethod11.after` are created.
* If an exception is thrown, a log entry named `testMethod11.afterFailure` is also created.
* A tag with a key of `testTag11` and a value of `test` is created.

=== Advanced Tag Setting

There are 3 different ways to add tags to a span. All of them are controlled by the `SpanTag` annotation.
The precedence is as follows:

. Try with a bean of `TagValueResolver` type and a provided name.
. If the bean name has not been provided, try to evaluate an expression.
We search for a `TagValueExpressionResolver` bean.
The default implementation uses SPEL expression resolution.
**IMPORTANT** You can only reference properties from the SPEL expression. Method execution is not allowed due to security constraints.
. If we do not find any expression to evaluate, return the `toString()` value of the parameter.

==== Custom extractor

The value of the tag for the following method is computed by an implementation of `TagValueResolver` interface.
Its class name has to be passed as the value of the `resolver` attribute.

Consider the following annotated method:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SpanTagAnnotationHandlerTests.java[tags=resolver_bean,indent=0]
----

Now further consider the following `TagValueResolver` bean implementation:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SpanTagAnnotationHandlerTests.java[tags=custom_resolver,indent=0]
----

The two preceding examples lead to setting a tag value equal to `Value from myCustomTagValueResolver`.

==== Resolving Expressions for a Value

Consider the following annotated method:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SpanTagAnnotationHandlerTests.java[tags=spel,indent=0]
----

No custom implementation of a `TagValueExpressionResolver` leads to evaluation of the SPEL expression, and a tag with a value of `4 characters` is set on the span.
If you want to use some other expression resolution mechanism, you can create your own implementation of the bean.

==== Using the `toString()` method

Consider the following annotated method:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/annotation/SpanTagAnnotationHandlerTests.java[tags=toString,indent=0]
----

Running the preceding method with a value of `15` leads to setting a tag with a String value of `"15"`.

== Customizations

The `Tracer` object is fully managed by sleuth, so you rarely need to affect it. That said,
Sleuth supports a number of `Customizer` types, that allow you to configure
anything not already done by Sleuth with auto-configuration or properties.

If you define one of the following as a `Bean`, Sleuth will invoke it to
customize behaviour:

* RpcTracingCustomizer - for RPC tagging and sampling policy
* HttpTracingCustomizer - for HTTP tagging and sampling policy
* MessagingTracingCustomizer - for messaging tagging and sampling policy
* CurrentTraceContextCustomizer - to integrate decorators such as correlation.
* BaggagePropagationCustomizer - for propagating baggage fields in process and over headers
* CorrelationScopeDecoratorCustomizer - for scope decorations such as MDC (logging) field correlation

=== HTTP

==== Data Policy

The default span data policy for HTTP requests is described in Brave:
https://github.com/openzipkin/brave/tree/master/instrumentation/http#span-data-policy

To add different data to the span, you need to register a bean of type
`brave.http.HttpRequestParser` or `brave.http.HttpResponseParser` based on when
the data is collected.

The bean names correspond to the request or response side, and whether it is
a client or server. For example, `sleuthHttpClientRequestParser` changes what
is collected before a client request is sent to the server.

For your convenience `@HttpClientRequestParser`, `@HttpClientResponseParser`
and corresponding server annotations can be used to inject the proper beans
or to  reference the bean names via their static String `NAME` fields.

Here's an example adding the HTTP url in addition to defaults:
[source,java]
----
@Configuration
class Config {
include::{project-root}/tests/spring-cloud-sleuth-instrumentation-mvc-tests/src/test/java/org/springframework/cloud/sleuth/instrument/web/TraceFilterWebIntegrationTests.java[tags=custom_parser,indent=2]
}
----

==== Sampling

If client /server sampling is required, just  register a bean of type
`brave.sampler.SamplerFunction<HttpRequest>` and name  the bean
`sleuthHttpClientSampler` for client sampler and `sleuthHttpServerSampler`
for server  sampler.

For your convenience the `@HttpClientSampler` and `@HttpServerSampler`
annotations can be used to inject the proper beans or to  reference the bean
names via their static String `NAME` fields.

Check out Brave's code to see an example of how to make a path-based sampler
https://github.com/openzipkin/brave/tree/master/instrumentation/http#sampling-policy

If you want to completely rewrite the `HttpTracing` bean you can use the `SkipPatternProvider`
interface to retrieve the URL `Pattern` for spans that should be not sampled. Below you can see
an example of usage of `SkipPatternProvider` inside a server side, `Sampler<HttpRequest>`.

[source,java]
----
@Configuration
class Config {
include::{project-root}/tests/spring-cloud-sleuth-instrumentation-mvc-tests/src/test/java/org/springframework/cloud/sleuth/instrument/web/TraceFilterWebIntegrationTests.java[tags=custom_server_sampler,indent=2]
}
----

=== `TracingFilter`

You can also modify the behavior of the `TracingFilter`, which is the component that is responsible for processing the input HTTP request and adding tags basing on the HTTP response.
You can customize the tags or modify the response headers by registering your own instance of the `TracingFilter` bean.

In the following example, we register the `TracingFilter` bean, add the `ZIPKIN-TRACE-ID` response header containing the current Span's trace id, and add a tag with key `custom` and a value `tag` to the span.

[source,java]
----
include::{project-root}/tests/spring-cloud-sleuth-instrumentation-mvc-tests/src/test/java/org/springframework/cloud/sleuth/instrument/web/TraceFilterIntegrationTests.java[tags=response_headers,indent=0]
----

=== Messaging

Sleuth automatically configures the `MessagingTracing` bean which serves as a
foundation for Messaging instrumentation such as Kafka or JMS.

If a customization of producer / consumer sampling of messaging traces is required,
just register a bean of type `brave.sampler.SamplerFunction<MessagingRequest>` and
name the bean `sleuthProducerSampler` for producer sampler and `sleuthConsumerSampler`
for consumer sampler.

For your convenience the `@ProducerSampler` and `@ConsumerSampler`
annotations can  be used to inject the proper beans or to reference the bean
names via their  static String `NAME` fields.

Ex. Here's a sampler that traces 100 consumer requests per second, except for
the "alerts" channel. Other requests will use a global rate provided by the
`Tracing` component.

[source,java]
----
@Configuration
class Config {
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/instrument/messaging/TraceMessagingAutoConfigurationIntegrationTests.java[tags=custom_messaging_server_sampler,indent=2]
}
----

For more, see https://github.com/openzipkin/brave/tree/master/instrumentation/messaging#sampling-policy

=== RPC

Sleuth automatically configures the `RpcTracing` bean which serves as a
foundation for RPC instrumentation such as gRPC or Dubbo.

If a customization of client / server sampling of the RPC traces is required,
just register a bean of type `brave.sampler.SamplerFunction<RpcRequest>` and
name the bean `sleuthRpcClientSampler` for client sampler and
`sleuthRpcServerSampler` for server sampler.

For your convenience the `@RpcClientSampler` and `@RpcServerSampler`
annotations can  be used to inject the proper beans or to reference the bean
names via their  static String `NAME` fields.

Ex. Here's a sampler that traces 100 "GetUserToken" server requests per second.
This  doesn't start new traces for requests to the health check service. Other
requests will use the global sampling configuration.

[source,java]
----
@Configuration
class Config {
include::{project-root}/tests/spring-cloud-sleuth-instrumentation-rpc-tests/src/test/java/org/springframework/cloud/sleuth/instrument/rpc/TraceRpcAutoConfigurationIntegrationTests.java[tags=custom_rpc_server_sampler,indent=2]
}
----

For more, see https://github.com/openzipkin/brave/tree/master/instrumentation/rpc#sampling-policy

=== Custom service name

By default, Sleuth assumes that, when you send a span to Zipkin, you want the span's service name to be equal to the value of the `spring.application.name` property.
That is not always the case, though.
There are situations in which you want to explicitly provide a different service name for all spans coming from your application.
To achieve that, you can pass the following property to your application to override that value (the example is for a service named `myService`):

[source,yaml]
----
spring.zipkin.service.name: myService
----

=== Customization of Reported Spans

Before reporting spans (for example, to Zipkin) you may want to modify that span in some way.
You can do so by implementing a `SpanHandler`.

In Sleuth, we generate spans with a fixed name.
Some users want to modify the name depending on values of tags.
You can implement the `SpanHandler` interface to alter that name.

The following example shows how to register two beans that implement `SpanHandler`:

[source,java]
----
include::{project-root}//spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/SpanHandlerTests.java[tags=spanHandler,indent=0]
----

The preceding example results in changing the name of the reported span to `foo bar`, just before it gets reported (for example, to Zipkin).

=== Host Locator

IMPORTANT: This section is about defining *host* from service discovery.
It is *NOT* about finding Zipkin through service discovery.

To define the host that corresponds to a particular span, we need to resolve the host name and port.
The default approach is to take these values from server properties.
If those are not set, we try to retrieve the host name from the network interfaces.

If you have the discovery client enabled and prefer to retrieve the host address from the registered instance in a service registry, you have to set the `spring.zipkin.locator.discovery.enabled` property (it is applicable for both HTTP-based and Stream-based span reporting), as follows:

[source,yaml]
----
spring.zipkin.locator.discovery.enabled: true
----

== Sending Spans to Zipkin

By default, if you add `spring-cloud-starter-zipkin` as a dependency to your project, when the span is closed, it is sent to Zipkin over HTTP.
The communication is asynchronous.
You can configure the URL by setting the `spring.zipkin.baseUrl` property, as follows:

[source,yaml]
----
spring.zipkin.baseUrl: https://192.168.99.100:9411/
----

If you want to find Zipkin through service discovery, you can pass the Zipkin's service ID inside the URL, as shown in the following example for `zipkinserver` service ID:

[source,yaml]
----
spring.zipkin.baseUrl: https://zipkinserver/
----

To disable this feature just set `spring.zipkin.discoveryClientEnabled` to `false.

When the Discovery Client feature is enabled, Sleuth uses
`LoadBalancerClient` to find the URL of the Zipkin Server. It means
that you can set up the load balancing configuration e.g. via Ribbon.

[source,yaml]
----
zipkinserver:
  ribbon:
    ListOfServers: host1,host2
----

If you have web, rabbit, activemq or kafka together on the classpath, you might need to pick the means by which you would like to send spans to zipkin.
To do so, set `web`, `rabbit`, `activemq` or `kafka` to the `spring.zipkin.sender.type` property.
The following example shows setting the sender type for `web`:

[source,yaml]
----
spring.zipkin.sender.type: web
----

To customize the `RestTemplate` that sends spans to Zipkin via HTTP, you can register
the `ZipkinRestTemplateCustomizer` bean.

[source,java]
----
@Configuration
class MyConfig {
	@Bean ZipkinRestTemplateCustomizer myCustomizer() {
		return new ZipkinRestTemplateCustomizer() {
			@Override
			void customize(RestTemplate restTemplate) {
				// customize the RestTemplate
			}
		};
	}
}
----

If, however, you would like to control the full process of creating the `RestTemplate`
object, you will have to create a bean of `zipkin2.reporter.Sender` type.

[source,java]
----
	@Bean Sender myRestTemplateSender(ZipkinProperties zipkin,
			ZipkinRestTemplateCustomizer zipkinRestTemplateCustomizer) {
		RestTemplate restTemplate = mySuperCustomRestTemplate();
		zipkinRestTemplateCustomizer.customize(restTemplate);
		return myCustomSender(zipkin, restTemplate);
	}
----

== Integrations

=== OpenTracing

Spring Cloud Sleuth is compatible with https://opentracing.io/[OpenTracing].
If you have OpenTracing on the classpath, we automatically register the OpenTracing `Tracer` bean.
If you wish to disable this, set `spring.sleuth.opentracing.enabled` to `false`

=== Runnable and Callable

If you wrap your logic in `Runnable` or `Callable`, you can wrap those classes in their Sleuth representative, as shown in the following example for `Runnable`:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=trace_runnable,indent=0]
----

The following example shows how to do so for `Callable`:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/documentation/SpringCloudSleuthDocTests.java[tags=trace_callable,indent=0]
----

That way, you ensure that a new span is created and closed for each execution.

=== Spring Cloud CircuitBreaker

If you have Spring Cloud CircuitBreaker on the classpath, we will wrap the passed command `Supplier` and the fallback `Function` in its trace representations. In order to disable this instrumentation set `spring.sleuth.circuitbreaker.enabled` to `false`.

=== RxJava

We registering a custom https://github.com/ReactiveX/RxJava/wiki/Plugins#rxjavaschedulershook[`RxJavaSchedulersHook`] that wraps all `Action0` instances in their Sleuth representative, which is called `TraceAction`.
The hook either starts or continues a span, depending on whether tracing was already going on before the Action was scheduled.
To disable the custom `RxJavaSchedulersHook`, set the `spring.sleuth.rxjava.schedulers.hook.enabled` to `false`.

You can define a list of regular expressions for thread names for which you do not want spans to be created.
To do so, provide a comma-separated list of regular expressions in the `spring.sleuth.rxjava.schedulers.ignoredthreads` property.

IMPORTANT: The suggest approach to reactive programming and Sleuth is to use
the Reactor support.

=== HTTP integration

Features from this section can be disabled by setting the `spring.sleuth.web.enabled` property with value equal to `false`.

==== HTTP Filter

Through the `TracingFilter`, all sampled incoming requests result in creation of a Span.
That Span's name is `http:` + the path to which the request was sent.
For example, if the request was sent to `/this/that` then the name will be `http:/this/that`.
You can configure which URIs you would like to skip by setting the `spring.sleuth.web.skipPattern` property.
If you have `ManagementServerProperties` on classpath, its value of `contextPath` gets appended to the provided skip pattern.
If you want to reuse the Sleuth's default skip patterns and just append your own, pass those patterns by using the `spring.sleuth.web.additionalSkipPattern`.

By default, all the spring boot actuator endpoints are automatically added to the skip pattern.
If you want to disable this behaviour set `spring.sleuth.web.ignore-auto-configured-skip-patterns`
to `true`.

To change the order of tracing filter registration, please set the
`spring.sleuth.web.filter-order` property.

To disable the filter that logs uncaught exceptions you can disable the
`spring.sleuth.web.exception-throwing-filter-enabled` property.

==== HandlerInterceptor

Since we want the span names to be precise, we use a `TraceHandlerInterceptor` that either wraps an existing `HandlerInterceptor` or is added directly to the list of existing `HandlerInterceptors`.
The `TraceHandlerInterceptor` adds a special request attribute to the given `HttpServletRequest`.
If the the `TracingFilter` does not see this attribute, it creates a "`fallback`" span, which is an additional span created on the server side so that the trace is presented properly in the UI.
If that happens, there is probably missing instrumentation.
In that case, please file an issue in Spring Cloud Sleuth.

==== Async Servlet support

If your controller returns a `Callable` or a `WebAsyncTask`, Spring Cloud Sleuth continues the existing span instead of creating a new one.

==== WebFlux support

Through `TraceWebFilter`, all sampled incoming requests result in creation of a Span.
That Span's name is `http:` + the path to which the request was sent.
For example, if the request was sent to `/this/that`, the name is `http:/this/that`.
You can configure which URIs you would like to skip by using the `spring.sleuth.web.skipPattern` property.
If you have `ManagementServerProperties` on the classpath, its value of `contextPath` gets appended to the provided skip pattern.
If you want to reuse Sleuth's default skip patterns and append your own, pass those patterns by using the `spring.sleuth.web.additionalSkipPattern`.

To change the order of tracing filter registration, please set the
`spring.sleuth.web.filter-order` property.

==== Dubbo RPC support

Via the integration with Brave, Spring Cloud Sleuth supports https://dubbo.apache.org/[Dubbo].
It's enough to add the `brave-instrumentation-dubbo` dependency:

[source,xml,indent=0]
----
<dependency>
    <groupId>io.zipkin.brave</groupId>
    <artifactId>brave-instrumentation-dubbo</artifactId>
</dependency>
----

You need to also set a `dubbo.properties` file with the following contents:

```properties
dubbo.provider.filter=tracing
dubbo.consumer.filter=tracing
```

You can read more about Brave - Dubbo integration https://github.com/openzipkin/brave/tree/master/instrumentation/dubbo-rpc[here].
An example of Spring Cloud Sleuth and Dubbo can be found https://github.com/openzipkin/sleuth-webmvc-example/compare/add-dubbo-tracing[here].

=== HTTP Client Integration

==== Synchronous Rest Template

We inject a `RestTemplate` interceptor to ensure that all the tracing information is passed to the requests.
Each time a call is made, a new Span is created.
It gets closed upon receiving the response.
To block the synchronous `RestTemplate` features, set `spring.sleuth.web.client.enabled` to `false`.

IMPORTANT: You have to register `RestTemplate` as a bean so that the interceptors get injected.
If you create a `RestTemplate` instance with a `new` keyword, the instrumentation does NOT work.

==== Asynchronous Rest Template

IMPORTANT: Starting with Sleuth `2.0.0`, we no longer register a bean of `AsyncRestTemplate` type.
It is up to you to create such a bean.
Then we instrument it.

To block the `AsyncRestTemplate` features, set `spring.sleuth.web.async.client.enabled` to `false`.
To disable creation of the default `TraceAsyncClientHttpRequestFactoryWrapper`, set `spring.sleuth.web.async.client.factory.enabled`
to `false`.
If you do not want to create `AsyncRestClient` at all, set `spring.sleuth.web.async.client.template.enabled` to `false`.

===== Multiple Asynchronous Rest Templates

Sometimes you need to use multiple implementations of the Asynchronous Rest Template.
In the following snippet, you can see an example of how to set up such a custom `AsyncRestTemplate`:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/instrument/web/client/MultipleAsyncRestTemplateTests.java[tags=custom_async_rest_template,indent=0]
----

==== `WebClient`

We inject a `ExchangeFilterFunction` implementation that creates a span and, through on-success and on-error callbacks, takes care of closing client-side spans.

To block this feature, set `spring.sleuth.web.client.enabled` to `false`.

IMPORTANT: You have to register `WebClient` as a bean so that the tracing instrumentation gets applied.
If you create a `WebClient` instance with a `new` keyword,  the instrumentation does NOT work.

==== Traverson

If you use the https://docs.spring.io/spring-hateoas/docs/current/reference/html/#client.traverson[Traverson] library, you can inject a `RestTemplate` as a bean into your Traverson object.
Since `RestTemplate` is already intercepted, you get full support for tracing in your client. The following pseudo code
shows how to do that:

[source,java]
----
@Autowired RestTemplate restTemplate;

Traverson traverson = new Traverson(URI.create("https://some/address"),
    MediaType.APPLICATION_JSON, MediaType.APPLICATION_JSON_UTF8).setRestOperations(restTemplate);
// use Traverson
----

==== Apache `HttpClientBuilder` and `HttpAsyncClientBuilder`

We instrument the `HttpClientBuilder` and `HttpAsyncClientBuilder` so that
tracing context gets injected to the sent requests.

To block these features, set `spring.sleuth.web.client.enabled` to `false`.

==== Netty `HttpClient`

We instrument the Netty's `HttpClient`.

To block this feature, set `spring.sleuth.web.client.enabled` to `false`.

IMPORTANT: You have to register `HttpClient` as a bean so that the instrumentation happens.
If you create a `HttpClient` instance with a `new` keyword, the instrumentation does NOT work.

==== `UserInfoRestTemplateCustomizer`

We instrument the Spring Security's `UserInfoRestTemplateCustomizer`.

To block this feature, set `spring.sleuth.web.client.enabled` to `false`.

=== Feign

By default, Spring Cloud Sleuth provides integration with Feign through `TraceFeignClientAutoConfiguration`.
You can disable it entirely by setting `spring.sleuth.feign.enabled` to `false`.
If you do so, no Feign-related instrumentation take place.

Part of Feign instrumentation is done through a `FeignBeanPostProcessor`.
You can disable it by setting `spring.sleuth.feign.processor.enabled` to `false`.
If you set it to `false`, Spring Cloud Sleuth does not instrument any of your custom Feign components.
However, all the default instrumentation is still there.

=== gRPC

Spring Cloud Sleuth provides instrumentation for https://grpc.io/[gRPC] through `TraceGrpcAutoConfiguration`. You can disable it entirely by setting `spring.sleuth.grpc.enabled` to `false`.

==== Variant 1

===== Dependencies
IMPORTANT: The gRPC integration relies on two external libraries to instrument clients and servers and both of those libraries must be on the class path to enable the instrumentation.

Maven:
```
		<dependency>
			<groupId>io.github.lognet</groupId>
			<artifactId>grpc-spring-boot-starter</artifactId>
		</dependency>
		<dependency>
			<groupId>io.zipkin.brave</groupId>
			<artifactId>brave-instrumentation-grpc</artifactId>
		</dependency>
```
Gradle:
```
    compile("io.github.lognet:grpc-spring-boot-starter")
    compile("io.zipkin.brave:brave-instrumentation-grpc")
```

===== Server Instrumentation

Spring Cloud Sleuth leverages grpc-spring-boot-starter to register Brave's gRPC server interceptor with all services annotated with `@GRpcService`.

===== Client Instrumentation

gRPC clients leverage a `ManagedChannelBuilder` to construct a `ManagedChannel` used to communicate to the gRPC server. The native `ManagedChannelBuilder` provides static methods as entry points for construction of `ManagedChannel` instances, however, this mechanism is outside the influence of the Spring application context.

IMPORTANT: Spring Cloud Sleuth provides a `SpringAwareManagedChannelBuilder` that can be customized through the Spring application context and injected by gRPC clients. *This builder must be used when creating `ManagedChannel` instances.*


Sleuth creates a `TracingManagedChannelBuilderCustomizer` which inject Brave's client interceptor into the `SpringAwareManagedChannelBuilder`.

==== Variant 2

https://github.com/yidongnan/grpc-spring-boot-starter[Grpc Spring Boot Starter] automatically detects the presence of Spring Cloud Sleuth and brave's instrumentation for gRPC and registers the necessary client and/or server tooling.

=== Asynchronous Communication

==== `@Async` Annotated methods

In Spring Cloud Sleuth, we instrument async-related components so that the tracing information is passed between threads.
You can disable this behavior by setting the value of `spring.sleuth.async.enabled` to `false`.

If you annotate your method with `@Async`, we automatically create a new Span with the following characteristics:

* If the method is annotated with `@SpanName`, the value of the annotation is the Span's name.
* If the method is not annotated with `@SpanName`, the Span name is the annotated method name.
* The span is tagged with the method's class name and method name.

==== `@Scheduled` Annotated Methods

In Spring Cloud Sleuth, we instrument scheduled method execution so that the tracing information is passed between threads.
You can disable this behavior by setting the value of `spring.sleuth.scheduled.enabled` to `false`.

If you annotate your method with `@Scheduled`, we automatically create a new span with the following characteristics:

* The span name is the annotated method name.
* The span is tagged with the method's class name and method name.

If you want to skip span creation for some `@Scheduled` annotated classes, you can set the `spring.sleuth.scheduled.skipPattern` with a regular expression that matches the fully qualified name of the `@Scheduled` annotated class.

==== Executor, ExecutorService, and ScheduledExecutorService

We provide `LazyTraceExecutor`, `TraceableExecutorService`, and `TraceableScheduledExecutorService`. Those implementations create spans each time a new task is submitted, invoked, or scheduled.

The following example shows how to pass tracing information with `TraceableExecutorService` when working with `CompletableFuture`:

[source,java]
----

include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/instrument/async/TraceableExecutorServiceTests.java[tags=completablefuture,indent=0]
----

IMPORTANT: Sleuth does not work with `parallelStream()` out of the box.
If you want to have the tracing information propagated through the stream, you have to use the approach with `supplyAsync(...)`, as shown earlier.

If there are beans that implement the `Executor` interface that you would like
to exclude from span creation, you can use the `spring.sleuth.async.ignored-beans`
property where you can provide a list of bean names.

===== Customization of Executors

Sometimes, you need to set up a custom instance of the `AsyncExecutor`.
The following example shows how to set up such a custom `Executor`:

[source,java]
----
include::{project-root}/spring-cloud-sleuth-core/src/test/java/org/springframework/cloud/sleuth/instrument/web/client/MultipleAsyncRestTemplateTests.java[tags=custom_executor,indent=0]
----

TIP: To ensure that your configuration gets post processed, remember
to add the `@Role(BeanDefinition.ROLE_INFRASTRUCTURE)` on your
`@Configuration` class

=== Messaging

Features from this section can be disabled by setting the `spring.sleuth.messaging.enabled` property with value equal to `false`.

==== Spring Integration and Spring Cloud Stream

Spring Cloud Sleuth integrates with https://projects.spring.io/spring-integration/[Spring Integration].
It creates spans for publish and subscribe events.
To disable Spring Integration instrumentation, set `spring.sleuth.integration.enabled` to `false`.

You can provide the `spring.sleuth.integration.patterns` pattern to explicitly provide the names of channels that you want to include for tracing.
By default, all channels but `hystrixStreamOutput` channel are included.

IMPORTANT: When using the `Executor` to build a Spring Integration `IntegrationFlow`, you must use the untraced version of the `Executor`.
Decorating the Spring Integration Executor Channel with `TraceableExecutorService` causes the spans to be improperly closed.

If you want to customize the way tracing context is read from and written to message headers,
it's enough for you to register beans of types:

* `Propagation.Setter<MessageHeaderAccessor, String>` - for writing headers to the message
* `Propagation.Getter<MessageHeaderAccessor, String>` - for reading headers from the message

==== Spring RabbitMq

We instrument the `RabbitTemplate` so that tracing headers get injected
into the message.

To block this feature, set `spring.sleuth.messaging.rabbit.enabled` to `false`.

==== Spring Kafka

We instrument the Spring Kafka's `ProducerFactory` and `ConsumerFactory`
so that tracing headers get injected into the created Spring Kafka's
`Producer` and `Consumer`.

To block this feature, set `spring.sleuth.messaging.kafka.enabled` to `false`.

==== Spring Kafka Streams

We instrument the `KafkaStreams` `KafkaClientSupplier` so that tracing headers
get injected into the `Producer` and `Consumer`s. A `KafkaStreamsTracing` bean
allows for further instrumentation through additional `TransformerSupplier` and
`ProcessorSupplier` methods.

To block this feature, set `spring.sleuth.messaging.kafka.streams.enabled` to `false`.

==== Spring JMS

We instrument the `JmsTemplate` so that tracing headers get injected
into the message. We also support `@JmsListener` annotated methods on the consumer side.

To block this feature, set `spring.sleuth.messaging.jms.enabled` to `false`.

IMPORTANT: We don't support baggage propagation for JMS

==== Spring Cloud AWS Messaging SQS

We instrument `@SqsListener` which is provided by `org.springframework.cloud:spring-cloud-aws-messaging`
so that tracing headers get extracted from the message and a trace gets put into the context.

To block this feature, set `spring.sleuth.messaging.sqs.enabled` to `false`.

=== Redis

We set `tracing` property to Lettcue `ClientResources` instance to enable Brave tracing built in Lettuce .
To disable Redis support, set the `spring.sleuth.redis.enabled` property to `false`.

=== Quartz

We instrument quartz jobs by adding Job/Trigger listeners to the Quartz Scheduler.

To turn off this feature, set the `spring.sleuth.quartz.enabled` property to `false`.

=== Project Reactor

For projects depending on Project Reactor such as Spring Cloud Gateway, we suggest turning the `spring.sleuth.reactor.decorate-on-each` option to `false`. That way an increased performance gain should be observed in comparison to the standard instrumentation mechanism. What this option does is it will wrap decorate `onLast` operator instead of `onEach` which will result in creation of far fewer objects. The downside of this is that when Project Reactor will change threads, the trace propagation will continue without issues, however anything relying on the `ThreadLocal` such as e.g. MDC entries can be buggy.

== Log integration
Sleuth configures the logging context with variables including the service name
(`%{spring.zipkin.service.name}`) and the trace ID (`%{traceId}`). These help
you connect logs with distributed traces and allow you choice in what tools you
use to troubleshoot your services.

If you use a log aggregating tool (such as https://www.elastic.co/products/kibana[Kibana], https://www.splunk.com/[Splunk], and others), you can order the events that took place.
An example from Kibana would resemble the following image:

image::https://raw.githubusercontent.com/spring-cloud/spring-cloud-sleuth/{branch}/docs/src/main/asciidoc/images/kibana.png[Log correlation with Kibana]

If you want to use https://www.elastic.co/guide/en/logstash/current/index.html[Logstash], the following listing shows the Grok pattern for Logstash:

[source]
filter {
  # pattern matching logback pattern
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp}\s+%{LOGLEVEL:severity}\s+\[%{DATA:service},%{DATA:trace},%{DATA:span}\]\s+%{DATA:pid}\s+---\s+\[%{DATA:thread}\]\s+%{DATA:class}\s+:\s+%{GREEDYDATA:rest}" }
  }
  date {
    match => ["timestamp", "ISO8601"]
  }
  mutate {
    remove_field => ["timestamp"]
  }
}

NOTE: If you want to use Grok together with the logs from Cloud Foundry, you have to use the following pattern:
[source]
filter {
  # pattern matching logback pattern
  grok {
    match => { "message" => "(?m)OUT\s+%{TIMESTAMP_ISO8601:timestamp}\s+%{LOGLEVEL:severity}\s+\[%{DATA:service},%{DATA:trace},%{DATA:span}\]\s+%{DATA:pid}\s+---\s+\[%{DATA:thread}\]\s+%{DATA:class}\s+:\s+%{GREEDYDATA:rest}" }
  }
  date {
    match => ["timestamp", "ISO8601"]
  }
  mutate {
    remove_field => ["timestamp"]
  }
}

=== JSON Logback with Logstash

Often, you do not want to store your logs in a text file but in a JSON file that Logstash can immediately pick.
To do so, you have to do the following (for readability, we pass the dependencies in the `groupId:artifactId:version` notation).

*Dependencies Setup*

. Ensure that Logback is on the classpath (`ch.qos.logback:logback-core`).
. Add Logstash Logback encode. For example, to use version `4.6`, add `net.logstash.logback:logstash-logback-encoder:4.6`.

*Logback Setup*

Consider the following example of a Logback configuration file (logback-spring.xml).

[source,xml]
-----
include::{project-root}/docs/src/main/asciidoc/logback-spring.xml[]
-----

That Logback configuration file:

* Logs information from the application in a JSON format to a `build/${spring.application.name}.json` file.
* Has commented out two additional appenders: console and standard log file.
* Has the same logging pattern as the one presented in the previous section.

NOTE: If you use a custom `logback-spring.xml`, you must pass the `spring.application.name` in the  `bootstrap` rather than the `application` property file.
Otherwise, your custom logback file does not properly read the property.

== Configuration properties

To see the list of all Sleuth related configuration properties please check link:appendix.html[the Appendix page].

